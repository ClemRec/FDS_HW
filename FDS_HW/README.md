
# FDS_Homework

The goal is to re-derive and implement logistic regression and optimize the parameters
with Gradient Descent and with the Newtonâ€™s method. Also, in this exercise you will re-derive and
implement Gassian Discriminant Analysis. We will use the files logistic_x.txt and logistic_y.txt.
The first contains the feature values $`x_1^{(i)}`$ and $`x_2^{(i)}`$ for the i-th data sample $`x^{(i)}`$. The second contains 12
the ground truth label $`y^{(i)}`$ for each corresponding data sample.

# Questions
## Question 1: Logistic Regression with Gradient Ascent

### Question 1.1
Write the equations for the log-likelihood, its gradient and the gradient ascent update rule.

### Question 1.2
Implementation of the logistic regression with gradient ascent.

## Question 2: Logistic Regression with the Newton's method
### Question 2.1
Derive the equations for the Hessian matric of the log-likelihood.

### Question 2.2
Implementation of the logistic regression with Newton's method.

## Question 3: Logistic Regression with non linear boundaries
### Question 3.1
Define new features e.g. of 2nd and 3rd degrees and learn a logistic regression classifier by using the new features, using the Newton's optimization algorithm.

### Question 3.2
Plot the computed non-linear boundary.

## Question 4: Guassian Discriminant Analysis
### Question 4.1
Implemente classification with Gradient Discriminant Analysis (GDA).

### Question 4.2
Plot the estimated likelihood functions and the decision boundary.


